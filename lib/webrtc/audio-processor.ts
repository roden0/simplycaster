/**\n * Audio Processor with FFmpeg.wasm\n * \n * Handles client-side audio processing, format conversion, and optimization\n * using FFmpeg.wasm for WebRTC recordings.\n */\n\n/**\n * Audio Processing Configuration\n */\nexport interface AudioProcessingConfig {\n  outputFormat: 'mp3' | 'wav' | 'ogg' | 'webm';\n  bitrate: number; // in kbps\n  sampleRate: number; // in Hz\n  channels: number; // 1 for mono, 2 for stereo\n  normalize: boolean;\n  noiseReduction: boolean;\n  compressionLevel: number; // 0-9 for quality vs size\n}\n\n/**\n * Processing Progress Information\n */\nexport interface ProcessingProgress {\n  stage: 'loading' | 'converting' | 'optimizing' | 'finalizing' | 'complete' | 'error';\n  progress: number; // 0-100\n  message: string;\n  timeRemaining?: number; // in seconds\n}\n\n/**\n * Audio Processing Result\n */\nexport interface AudioProcessingResult {\n  processedBlob: Blob;\n  originalSize: number;\n  processedSize: number;\n  compressionRatio: number;\n  duration: number;\n  format: string;\n  processingTime: number;\n}\n\n/**\n * Audio Processor Events\n */\nexport interface AudioProcessorEvents {\n  'progress': (progress: ProcessingProgress) => void;\n  'complete': (result: AudioProcessingResult) => void;\n  'error': (error: Error) => void;\n}\n\n/**\n * Audio Processor Class\n */\nexport class AudioProcessor {\n  private config: AudioProcessingConfig;\n  private eventListeners = new Map<keyof AudioProcessorEvents, Function[]>();\n  private ffmpegLoaded = false;\n  private ffmpeg: any = null; // FFmpeg instance\n  private isProcessing = false;\n\n  constructor(config?: Partial<AudioProcessingConfig>) {\n    this.config = {\n      outputFormat: 'mp3',\n      bitrate: 128,\n      sampleRate: 44100,\n      channels: 2,\n      normalize: true,\n      noiseReduction: false,\n      compressionLevel: 5,\n      ...config\n    };\n  }\n\n  /**\n   * Initialize FFmpeg.wasm\n   */\n  async initialize(): Promise<void> {\n    if (this.ffmpegLoaded) {\n      return;\n    }\n\n    try {\n      this.emitProgress({\n        stage: 'loading',\n        progress: 0,\n        message: 'Loading FFmpeg.wasm...'\n      });\n\n      // Dynamic import of FFmpeg.wasm\n      const { FFmpeg } = await import('https://unpkg.com/@ffmpeg/ffmpeg@0.12.7/dist/esm/index.js');\n      const { fetchFile, toBlobURL } = await import('https://unpkg.com/@ffmpeg/util@0.12.1/dist/esm/index.js');\n      \n      this.ffmpeg = new FFmpeg();\n      \n      // Load FFmpeg core\n      const baseURL = 'https://unpkg.com/@ffmpeg/core@0.12.4/dist/esm';\n      await this.ffmpeg.load({\n        coreURL: await toBlobURL(`${baseURL}/ffmpeg-core.js`, 'text/javascript'),\n        wasmURL: await toBlobURL(`${baseURL}/ffmpeg-core.wasm`, 'application/wasm'),\n      });\n\n      this.ffmpegLoaded = true;\n      \n      this.emitProgress({\n        stage: 'loading',\n        progress: 100,\n        message: 'FFmpeg.wasm loaded successfully'\n      });\n      \n      console.log('FFmpeg.wasm initialized successfully');\n    } catch (error) {\n      console.error('Failed to initialize FFmpeg.wasm:', error);\n      this.emit('error', new Error(`Failed to initialize FFmpeg.wasm: ${error}`));\n      throw error;\n    }\n  }\n\n  /**\n   * Process audio blob\n   */\n  async processAudio(audioBlob: Blob, filename?: string): Promise<AudioProcessingResult> {\n    if (!this.ffmpegLoaded) {\n      await this.initialize();\n    }\n\n    if (this.isProcessing) {\n      throw new Error('Audio processing already in progress');\n    }\n\n    this.isProcessing = true;\n    const startTime = Date.now();\n    const inputFilename = filename || `input.${this.getInputFormat(audioBlob.type)}`;\n    const outputFilename = `output.${this.config.outputFormat}`;\n\n    try {\n      this.emitProgress({\n        stage: 'converting',\n        progress: 10,\n        message: 'Preparing audio for processing...'\n      });\n\n      // Write input file to FFmpeg filesystem\n      const inputData = new Uint8Array(await audioBlob.arrayBuffer());\n      await this.ffmpeg.writeFile(inputFilename, inputData);\n\n      this.emitProgress({\n        stage: 'converting',\n        progress: 30,\n        message: 'Converting audio format...'\n      });\n\n      // Build FFmpeg command\n      const command = this.buildFFmpegCommand(inputFilename, outputFilename);\n      console.log('FFmpeg command:', command.join(' '));\n\n      // Execute FFmpeg command\n      await this.ffmpeg.exec(command);\n\n      this.emitProgress({\n        stage: 'optimizing',\n        progress: 80,\n        message: 'Optimizing audio...'\n      });\n\n      // Read output file\n      const outputData = await this.ffmpeg.readFile(outputFilename);\n      const processedBlob = new Blob([outputData], { \n        type: this.getMimeType(this.config.outputFormat) \n      });\n\n      this.emitProgress({\n        stage: 'finalizing',\n        progress: 95,\n        message: 'Finalizing processed audio...'\n      });\n\n      // Calculate metrics\n      const originalSize = audioBlob.size;\n      const processedSize = processedBlob.size;\n      const compressionRatio = originalSize > 0 ? processedSize / originalSize : 1;\n      const processingTime = Date.now() - startTime;\n      const duration = await this.getAudioDuration(processedBlob);\n\n      // Cleanup FFmpeg filesystem\n      await this.ffmpeg.deleteFile(inputFilename);\n      await this.ffmpeg.deleteFile(outputFilename);\n\n      const result: AudioProcessingResult = {\n        processedBlob,\n        originalSize,\n        processedSize,\n        compressionRatio,\n        duration,\n        format: this.config.outputFormat,\n        processingTime\n      };\n\n      this.emitProgress({\n        stage: 'complete',\n        progress: 100,\n        message: 'Audio processing completed successfully'\n      });\n\n      this.emit('complete', result);\n      console.log('Audio processing completed:', result);\n      \n      return result;\n    } catch (error) {\n      console.error('Audio processing failed:', error);\n      const processingError = new Error(`Audio processing failed: ${error}`);\n      \n      this.emitProgress({\n        stage: 'error',\n        progress: 0,\n        message: `Processing failed: ${error}`\n      });\n      \n      this.emit('error', processingError);\n      throw processingError;\n    } finally {\n      this.isProcessing = false;\n    }\n  }\n\n  /**\n   * Process multiple audio chunks and combine them\n   */\n  async processMultipleChunks(chunks: Blob[], participantName?: string): Promise<AudioProcessingResult> {\n    if (!this.ffmpegLoaded) {\n      await this.initialize();\n    }\n\n    if (chunks.length === 0) {\n      throw new Error('No audio chunks provided');\n    }\n\n    if (this.isProcessing) {\n      throw new Error('Audio processing already in progress');\n    }\n\n    this.isProcessing = true;\n    const startTime = Date.now();\n    const outputFilename = `${participantName || 'combined'}.${this.config.outputFormat}`;\n\n    try {\n      this.emitProgress({\n        stage: 'converting',\n        progress: 5,\n        message: `Processing ${chunks.length} audio chunks...`\n      });\n\n      // Write all chunks to FFmpeg filesystem\n      const inputFiles: string[] = [];\n      for (let i = 0; i < chunks.length; i++) {\n        const filename = `chunk_${i.toString().padStart(4, '0')}.webm`;\n        const chunkData = new Uint8Array(await chunks[i].arrayBuffer());\n        await this.ffmpeg.writeFile(filename, chunkData);\n        inputFiles.push(filename);\n        \n        this.emitProgress({\n          stage: 'converting',\n          progress: 5 + (i / chunks.length) * 30,\n          message: `Processing chunk ${i + 1}/${chunks.length}...`\n        });\n      }\n\n      this.emitProgress({\n        stage: 'converting',\n        progress: 40,\n        message: 'Combining audio chunks...'\n      });\n\n      // Create concat file list\n      const concatList = inputFiles.map(file => `file '${file}'`).join('\\n');\n      await this.ffmpeg.writeFile('concat_list.txt', concatList);\n\n      // Build FFmpeg command for concatenation and processing\n      const command = this.buildConcatCommand('concat_list.txt', outputFilename);\n      console.log('FFmpeg concat command:', command.join(' '));\n\n      // Execute FFmpeg command\n      await this.ffmpeg.exec(command);\n\n      this.emitProgress({\n        stage: 'optimizing',\n        progress: 80,\n        message: 'Optimizing combined audio...'\n      });\n\n      // Read output file\n      const outputData = await this.ffmpeg.readFile(outputFilename);\n      const processedBlob = new Blob([outputData], { \n        type: this.getMimeType(this.config.outputFormat) \n      });\n\n      // Calculate metrics\n      const originalSize = chunks.reduce((total, chunk) => total + chunk.size, 0);\n      const processedSize = processedBlob.size;\n      const compressionRatio = originalSize > 0 ? processedSize / originalSize : 1;\n      const processingTime = Date.now() - startTime;\n      const duration = await this.getAudioDuration(processedBlob);\n\n      // Cleanup FFmpeg filesystem\n      await this.ffmpeg.deleteFile('concat_list.txt');\n      await this.ffmpeg.deleteFile(outputFilename);\n      for (const file of inputFiles) {\n        await this.ffmpeg.deleteFile(file);\n      }\n\n      const result: AudioProcessingResult = {\n        processedBlob,\n        originalSize,\n        processedSize,\n        compressionRatio,\n        duration,\n        format: this.config.outputFormat,\n        processingTime\n      };\n\n      this.emitProgress({\n        stage: 'complete',\n        progress: 100,\n        message: 'Multi-chunk audio processing completed successfully'\n      });\n\n      this.emit('complete', result);\n      console.log('Multi-chunk audio processing completed:', result);\n      \n      return result;\n    } catch (error) {\n      console.error('Multi-chunk audio processing failed:', error);\n      const processingError = new Error(`Multi-chunk audio processing failed: ${error}`);\n      \n      this.emitProgress({\n        stage: 'error',\n        progress: 0,\n        message: `Processing failed: ${error}`\n      });\n      \n      this.emit('error', processingError);\n      throw processingError;\n    } finally {\n      this.isProcessing = false;\n    }\n  }\n\n  /**\n   * Get audio duration using Web Audio API\n   */\n  private async getAudioDuration(audioBlob: Blob): Promise<number> {\n    try {\n      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();\n      const arrayBuffer = await audioBlob.arrayBuffer();\n      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);\n      audioContext.close();\n      return audioBuffer.duration;\n    } catch (error) {\n      console.warn('Failed to get audio duration:', error);\n      return 0;\n    }\n  }\n\n  /**\n   * Build FFmpeg command for single file processing\n   */\n  private buildFFmpegCommand(inputFile: string, outputFile: string): string[] {\n    const command = ['-i', inputFile];\n\n    // Audio codec and format settings\n    if (this.config.outputFormat === 'mp3') {\n      command.push('-codec:a', 'libmp3lame');\n    } else if (this.config.outputFormat === 'ogg') {\n      command.push('-codec:a', 'libvorbis');\n    } else if (this.config.outputFormat === 'wav') {\n      command.push('-codec:a', 'pcm_s16le');\n    }\n\n    // Bitrate\n    if (this.config.outputFormat !== 'wav') {\n      command.push('-b:a', `${this.config.bitrate}k`);\n    }\n\n    // Sample rate\n    command.push('-ar', this.config.sampleRate.toString());\n\n    // Channels\n    command.push('-ac', this.config.channels.toString());\n\n    // Normalization\n    if (this.config.normalize) {\n      command.push('-af', 'loudnorm');\n    }\n\n    // Noise reduction\n    if (this.config.noiseReduction) {\n      if (this.config.normalize) {\n        command[command.length - 1] += ',highpass=f=80,lowpass=f=8000';\n      } else {\n        command.push('-af', 'highpass=f=80,lowpass=f=8000');\n      }\n    }\n\n    // Quality settings\n    if (this.config.outputFormat === 'mp3') {\n      command.push('-q:a', this.config.compressionLevel.toString());\n    }\n\n    // Output file\n    command.push(outputFile);\n\n    return command;\n  }\n\n  /**\n   * Build FFmpeg command for concatenating multiple files\n   */\n  private buildConcatCommand(concatFile: string, outputFile: string): string[] {\n    const command = ['-f', 'concat', '-safe', '0', '-i', concatFile];\n\n    // Use the same processing options as single file\n    const processingOptions = this.buildFFmpegCommand('dummy', 'dummy');\n    // Remove input and output from processing options\n    const filteredOptions = processingOptions.slice(2, -1);\n    command.push(...filteredOptions);\n\n    command.push(outputFile);\n    return command;\n  }\n\n  /**\n   * Get input format from MIME type\n   */\n  private getInputFormat(mimeType: string): string {\n    if (mimeType.includes('webm')) return 'webm';\n    if (mimeType.includes('mp4')) return 'mp4';\n    if (mimeType.includes('ogg')) return 'ogg';\n    if (mimeType.includes('wav')) return 'wav';\n    return 'webm'; // Default\n  }\n\n  /**\n   * Get MIME type for output format\n   */\n  private getMimeType(format: string): string {\n    switch (format) {\n      case 'mp3': return 'audio/mpeg';\n      case 'wav': return 'audio/wav';\n      case 'ogg': return 'audio/ogg';\n      case 'webm': return 'audio/webm';\n      default: return 'audio/mpeg';\n    }\n  }\n\n  /**\n   * Check if FFmpeg.wasm is supported\n   */\n  static isSupported(): boolean {\n    return !!(window.SharedArrayBuffer && window.WebAssembly);\n  }\n\n  /**\n   * Get processing capabilities\n   */\n  getCapabilities(): {\n    supportedInputFormats: string[];\n    supportedOutputFormats: string[];\n    maxFileSize: number;\n    features: string[];\n  } {\n    return {\n      supportedInputFormats: ['webm', 'mp4', 'ogg', 'wav', 'mp3'],\n      supportedOutputFormats: ['mp3', 'wav', 'ogg', 'webm'],\n      maxFileSize: 100 * 1024 * 1024, // 100MB\n      features: [\n        'format conversion',\n        'bitrate adjustment',\n        'sample rate conversion',\n        'channel mixing',\n        'audio normalization',\n        'noise reduction',\n        'multi-chunk concatenation'\n      ]\n    };\n  }\n\n  /**\n   * Update processing configuration\n   */\n  updateConfig(newConfig: Partial<AudioProcessingConfig>): void {\n    this.config = { ...this.config, ...newConfig };\n  }\n\n  /**\n   * Add event listener\n   */\n  on<K extends keyof AudioProcessorEvents>(event: K, listener: AudioProcessorEvents[K]): void {\n    if (!this.eventListeners.has(event)) {\n      this.eventListeners.set(event, []);\n    }\n    this.eventListeners.get(event)!.push(listener);\n  }\n\n  /**\n   * Remove event listener\n   */\n  off<K extends keyof AudioProcessorEvents>(event: K, listener: AudioProcessorEvents[K]): void {\n    const listeners = this.eventListeners.get(event);\n    if (listeners) {\n      const index = listeners.indexOf(listener);\n      if (index > -1) {\n        listeners.splice(index, 1);\n      }\n    }\n  }\n\n  /**\n   * Emit event\n   */\n  private emit<K extends keyof AudioProcessorEvents>(event: K, ...args: Parameters<AudioProcessorEvents[K]>): void {\n    const listeners = this.eventListeners.get(event);\n    if (listeners) {\n      listeners.forEach(listener => {\n        try {\n          (listener as any)(...args);\n        } catch (error) {\n          console.error(`Error in audio processor event listener for ${event}:`, error);\n        }\n      });\n    }\n  }\n\n  /**\n   * Emit progress update\n   */\n  private emitProgress(progress: ProcessingProgress): void {\n    this.emit('progress', progress);\n  }\n\n  /**\n   * Cleanup resources\n   */\n  async cleanup(): void {\n    if (this.ffmpeg && this.ffmpegLoaded) {\n      try {\n        // FFmpeg.wasm doesn't have a specific cleanup method\n        // but we can clear the event listeners\n        this.eventListeners.clear();\n        console.log('Audio processor cleaned up');\n      } catch (error) {\n        console.error('Error during audio processor cleanup:', error);\n      }\n    }\n  }\n}"